# The dangers of our information ecosystem
**Keywords** 
Digital identities, existencial risks,mass communication, sense-making, manipulation, institution,behaviour, social media, disinformation
  
## Introduction
Whether in our time or in the past, our behaviour has always been influenced by external factors, like the environment in which we live, the people around us, etc. Various entities such as companies, media outlets, and governments have the ability to shape our decision-making and discourage independent thought. The problem today is that since the invention of mass communication (the press, television), and then the Internet, these external players are increasingly omnipresent in our lives, whether we are aware of it or not, and have a major influence on the decisions we make. 

So we can then ask ourselves : How does today’s mass communication, boosted by technology leads to existential risks? How can we be more aware of what information are thrown at us by companies, governments, and medias?

In this essay, we will first inform ourselves about the informational dangers inherent in our hyper-connected society, such as disinformation or the manipalutation of public opionion by major institutions, and the resulting creation of information bubbles. Then, we will focus on big companies and what they control, censor, and encourage. And finally, all this might help us understand how these actions can lead to humanity's downfall, by boosting internal conflicts or disputes between countries. All of these reflexions can then motivate us to develop our awareness of these issues so that we can better position ourselves in our society and be mindful of our choices.

## I. Threats to the Information Ecosystem
### A. Disinformation
Disinformation water down the quality of information available online. It can make it difficult to distinguish between reliable and unreliable sources, thereby weakening trust in traditional media and institutions.

In healthcare, disinformation can spread false information about vaccines, medical treatments or health crises. This can endanger public health by discouraging vaccination, encouraging risky behaviour or creating mistrust in the health authorities. For example, during the COVID crisis, social networks were in turmoil. With too much information being relayed, it can quickly become obsolete or simply irrelevant. What's more, a lot of influencers relayed a lot of information during this period. TalkWalker, an online social media surveillance programme, estimated that references to COVID-19 on social media reached 40.2 million times between May 12, 2020, and May 18, 2020. (M. Gottlieb, 2020). Influencers, whether they work in the medical field or not, each have their own community and will further boost the circulation of rumours on social networks, such as whether or not to get vaccinated.

On top of all this, disinformation can lead to widespread mistrust, undermining social cohesion. When people are repeatedly exposed to false information, they can become more sceptical and less inclined to believe even factual, well-verified information. And when there are constant doubts about the accuracy of the information they receive, it can undermine the mutual trust necessary for a society to function properly. 

Misinformation can be countered by actions taken by the media, digital platforms and governments to promote accurate, diverse and transparent information. However, large institutions will sometimes use their power of moderation for their own ends.

### B. Manipulation of Public Opinion by institutions
The deployment of technology to influence behaviour has become an integral aspect of modern societies. For example, during the 2016 US presidential elections, foreign entities exploited social media platforms to spread disinformation, sow discord and influence public opinion. 

Social media has been increasingly analysed by a lot of countries for its perceptual management and psychological manipulation, which can be used as a war tool to shape ideas, redesign society, increase sensitivity, and strengthen social responses, ultimately weakening the administration, society, military, or economy of a country.  In 2011, the US Defense Advanced Research Projects Agency published a plan created with the sole aim of improving the digital presence of US forces and supporting them in guiding public opinion in a professional manner (Chen, L., Chen, J. and Xia, C.,2022). The plan dates back more than 10 years and has undoubtedly been perfected over the years thanks to the development of new online social platforms.

Another more accessible example is the film 'Don't look up' on the Netflix platform. The film is a satire that tackles the theme of inaction in the face of an existential threat, symbolised by the discovery of a deadly comet heading for Earth. The issues at stake in the film highlight the difficulty of mobilising public attention on serious problems due to media manipulation, political indifference and social polarisation. While scientists predict the end of humanity, the President herself promotes a strategy of denial on social networks aimed at reassuring the population, with the sole aim of maintaining her power and her hold over the population. 

(https://youtu.be/JQERWWbnA5c?si=mKic55LmhmFjw9Ao)

The clip you can see is a good illustration of how institutions can distort reality and manipulate public opinion: all the President needs to do to manipulate a whole section of the population is to boost the egos of her listeners, by making fun of those who are afraid, and by using an enticing slogan. It also shows the extent to which over-frequent use of social networks can lead to the polarisation of society, as in this film.

### C. Information bubbles
Algorithms, by calculating regularities in behaviour to establish a user profile, contribute to a form of isolation for Internet users. In reality, each person accesses a different version of the Web, which locks them into a "unique and optimised" bubble.
-->Extreme polarisation of society : Information bubbles foster a sense of group identity and solidarity among like-minded individuals, making it harder for them to question their beliefs or consider alternative perspectives.

https://link-springer-com.uniessexlib.idm.oclc.org/chapter/10.1007/978-3-030-93413-2_15#Sec4 

## II. Control of Information by Companies
### A. Power of the technological giants
Social networks, search engines, and messaging services are all owned by technological giants.
They have content moderation standards in place to filter material published on their platforms. They can eliminate content that is violent, hateful, or violates the platform's regulations. 
In several occasions, companies have been criticised for dubious censorship policies. For example, deleting certain political content, banning accounts, or limiting the exposure of specific speakers might be interpreted as acts of censorship, raising discussions over free expression.
These algorithms decide what information is shown to a user and have the ability to affect the media agenda by favouring certain issues over others. In this sense, technology behemoths have an impact on the visibility of specific content as well as the moulding of public opinion, which can create as we saw before information bubbles.

another example : the sponsorised tweets promoted by twitter

https://www-sciencedirect-com.uniessexlib.idm.oclc.org/science/article/pii/S0377221720308249?via%3Dihub#sec0004
The responsibility of social media in times of societal and political manipulation
Reisach, Ulrike 

### B. Surveillance and Privacy
Data collection on social media by companies, or in our daily lives with smart objects.

Another examples : social commerce and how it affects our privacy.
The article "Investigating online social media users’ behaviors for social commerce recommendations" indicates "With business concepts of online shopping and social networks, social commerce connects sellers, and consumers span over websites and social platforms".
https://www-sciencedirect-com.uniessexlib.idm.oclc.org/science/article/pii/S0160791X21001305?via%3Dihub 

Social commerce platforms collect extensive user data, including browsing history, preferences, and interactions, to create detailed profiles for targeted advertising. Then, they can share this data with third-party advertisers that could increase the risk of unauthorized access or misuse. Some companies use tracking technologies, like cookies and pixels to monitor user behavior and analyse it to show more pertinent and personnalised information to eacher user.Social commerce, by facilitating payments online, can encore more people to pay on social platform, which could be dangerous if those payment informations are revealed : in the event of a data breach, users' financial details may be compromised, leading to potential fraud or identity theft. 

### C. International challenges
Influence of disinformation on international relations + Manipulation of information for geopolitical purposes nécessité global cooperation to mitigate these risks

Theorising digital disinformation in international relations
la Cour, Christina
https://link-springer-com.uniessexlib.idm.oclc.org/article/10.1057/s41311-020-00215-x

##  III. Impact on Existing Risks and Areas for Improvement
### A. Existing risks
Escalation of conflicts :
- **Collective misinformation can lead to mistrust** of institutions, democratic processes and other foundations of society, **resulting in social conflict, political instability and even crisis**
- the spread of information bubbles **divide communities, make constructive dialogue difficult and compromise society's ability to tackle common challenges**
- **Trust is essential for institutions, governments and social interactions to function smoothly.** If the population of a country does not trust their governement anymore, its country will no longer be properly managed, either economically or politically. Some groups within the population may also want to overthrow the government they no longer trust, leading to internal conflict and civil war.
- In the event of an actual war, social media networks can serve as a tool for indirect offensives, encompassing covert media manipulation, dissemination of rumors, provocation of internal conflicts within the targeted party, and the spread of tension and negative emotions(Chen, L., Chen, J. and Xia, C.,2022).
- 
### B. Areas for improvement and sense-making
Raising awareness, corporate transparency ,International cooperation to develop common standards for information management
Sense making: be subjective, look at sources

## image credit
## references
- S;, G.M. (no date) Information and disinformation: Social media in the COVID-19 crisis, Academic emergency medicine : official journal of the Society for Academic Emergency Medicine. Available at: https://pubmed.ncbi.nlm.nih.gov/32474977/ (Accessed: 11 December 2023).
- Chen, L., Chen, J. and Xia, C. (2022) ‘Social network behavior and public opinion manipulation’, Journal of Information Security and Applications, 64, p. 103060. doi:10.1016/j.jisa.2021.103060. 


## Hyperlinks
[This](checklist.md) is an internal link to another page on your site. 

And [this](https://duckduckgo.com/?q=existential+risks&t=brave&ia=web&iai=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DdzlxU3g7hUY) is an external link to web page on another website. 

## Embedding images
Below you see an example of embedding an image that is found in this repository's assets/img folder: 

![Plain VR map](assets/img/vr-map-plain.svg)

Below you see an example of embedding an image that is found in another repository:

![](https://khofstadter.com/assets/img/2005-04-01-khofstadter-painting-chien.jpg). 

## Embedding video players

<iframe width="560" height="315" src="https://www.youtube.com/embed/lfPJ7Tz4JGs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

## More examples
Make sure you check out the [Markdown language](https://guides.github.com/features/mastering-markdown/) guide. 


